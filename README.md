# RAG Sandbox

A lightweight sandbox for building and understanding a **Retrieval-Augmented Generation (RAG)** pipeline using Python, LangChain, and FAISS.

This project is intentionally minimal and learning-focused. The goal is to understand how each layer of a RAG system works before introducing higher-level abstractions.

---

## ğŸ¯ Purpose

* Learn how documents become searchable vectors
* Make retrieval predictable and debuggable
* Understand how metadata flows through a RAG system
* Establish a solid foundation for adding memory and agent behavior later

---

## ğŸ§  Conceptual Pipeline

```
Documents (PDF / Text)
        â†“
Load
        â†“
Chunk
        â†“
Chunk Objects (with metadata)
        â†“
LangChain Documents
        â†“
Embeddings
        â†“
FAISS Vector Store
        â†“
Similarity Search
        â†“
Retrieved Chunks
        â†“
LLM Prompt
        â†“
Answer
```

---

## ğŸ“ Project Structure

```
rag_sandbox/
â”‚
â”œâ”€ ExampleData/            # Sample PDFs
â”‚
â”œâ”€ RagIntake.py            # Loads PDFs, chunks text, filters junk, creates Chunk objects
â”œâ”€ ChunkClass.py           # Dataclass definition for Chunk
â”œâ”€ VectorStore.py          # Builds FAISS index and runs similarity searches
â”‚
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## ğŸ“¦ Chunk Object

Each chunk is represented internally as a dataclass:

* `chunk_id`  â€“ unique identifier
* `content`   â€“ chunk text
* `page`      â€“ page number
* `source`    â€“ source file

Chunks are converted into LangChain `Document` objects before being inserted into FAISS.

---

## ğŸ“š Metadata

Every stored vector contains metadata:

```
{
  "chunk_id": "...",
  "page": 12,
  "source": "ExampleData/file.pdf"
}
```

This enables:

* Tracing where an answer came from
* Debugging retrieval quality
* Adding citations later

---

## ğŸ” Retrieval

FAISS is used with **L2 distance**.

Two common calls:

* `similarity_search()` â†’ returns Documents
* `similarity_search_with_score()` â†’ returns (Document, distance)

Smaller distance = more similar.

---

## âœ… Thresholding

To avoid hallucinations:

1. Retrieve top-k results (e.g., k=5)
2. Inspect best distance
3. If best distance > threshold â†’ return "Information not found"

Threshold is determined empirically by testing good vs bad queries.

---

## ğŸ§ª Basic Workflow

1. Place PDFs in `ExampleData/`
2. Run `RagIntake.py`

   * Loads and chunks documents
   * Creates Chunk objects
3. Run `VectorStore.py`

   * Creates embeddings
   * Builds FAISS index
   * Stores Documents
   * Runs similarity queries

---

## ğŸ§  Current Capabilities

* PDF loading
* Recursive chunking
* Junk filtering
* Chunk â†’ Document conversion
* FAISS vector store
* Similarity search
* Metadata returned with results

---

## ğŸš§ Planned Extensions

* Retrieval score threshold gating
* Logging similarity scores
* Conversation memory
* LangGraph + MemorySaver
* Answer citations
* Persist FAISS index to disk

---

## ğŸ“– References

* LangChain RAG Tutorial
* LangChain FAISS Integration
* LangChain Memory Concepts

---

## âš ï¸ Notes

This repository prioritizes clarity over optimization.
Expect refactors as understanding improves.

---

## ğŸ§‘â€ğŸ’» Author

Joel Falconer
